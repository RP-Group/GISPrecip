# -*- coding: utf-8 -*-
"""
/***************************************************************************
 GISPrecip
                                 A QGIS plugin
 Plugin that predicts the surface precipitation from GMI data.
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2025-07-11
        git sha              : $Format:%H$
        copyright            : (C) 2025 by Gabriel Rocha Pinto
        email                : gabriel.rocha.pinto@outlook.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""
from qgis.PyQt.QtCore import QSettings, QTranslator, QCoreApplication, QRegExp, QThread, QObject, pyqtSignal, pyqtSlot
from qgis.PyQt.QtGui import QIcon, QRegExpValidator
from qgis.PyQt.QtWidgets import QAction, QFileDialog, QTableWidgetItem, QLabel, QComboBox, QFormLayout, QLineEdit, QSpinBox, QDoubleSpinBox
from qgis.core import QgsProject, QgsRasterLayer
from qgis.core import QgsSingleBandPseudoColorRenderer, QgsColorRampShader, QgsRasterShader, QgsStyle
from qgis.gui import QgsSingleBandPseudoColorRendererWidget

import traceback
import inspect
from collections import deque
import numpy as np

from netCDF4 import Dataset

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, mean_absolute_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

from scipy.stats import pearsonr
from imblearn.under_sampling import RandomUnderSampler

from scipy.interpolate import griddata
from statsmodels.regression.linear_model import RegressionModel

# Initialize Qt resources from file resources.py
from .resources import *
# Import the code for the dialog
from .GIS_Precip_dialog import GISPrecipDialog
import os.path
from pathlib import Path
import re

import pickle

class TaskQueue:
    def __init__(self, dlg):
        self.dlg = dlg
        self.queue = deque()
        self._bg_thread = None
        self._bg_worker = None

    def add_task(self, fn, *fn_args, on_finished=None, **fn_kwargs):
        """
        Add a task to the queue.
        fn: function to run in background
        on_finished: called in main thread with fn's return values
        """
        self.queue.append((fn, fn_args, fn_kwargs, on_finished))
        if not self.is_running():
            self._start_next_task()

    def is_running(self):
        return self._bg_thread is not None and self._bg_thread.isRunning()

    def _start_next_task(self):
        if not self.queue:
            return  # nothing left to run

        fn, fn_args, fn_kwargs, on_finished = self.queue.popleft()

        class Worker(QObject):
            finished = pyqtSignal(object)  # carries result (can be tuple)
            log = pyqtSignal(str)

            def __init__(self, fn, args, kwargs):
                super().__init__()
                self.fn = fn
                self.args = args
                self.kwargs = kwargs

            @pyqtSlot()
            def run(self):
                try:
                    self.log.emit("Thread started: running function...")
                    result = self.fn(*self.args, **self.kwargs)
                    self.log.emit("Thread finished: function completed.")
                except Exception as e:
                    import traceback
                    tb = traceback.format_exc()
                    self.log.emit(f"Exception in thread: {e}\n{tb}")
                    result = None
                finally:
                    self.finished.emit(result)

        # Keep objects alive: store as attributes AND (optionally) parent the thread.
        thread = QThread(self.dlg) # parent helps keep it alive
        worker = Worker(fn, fn_args, fn_kwargs)
        worker.moveToThread(thread)

        # Connections
        thread.started.connect(worker.run)
        worker.finished.connect(thread.quit)
        worker.finished.connect(worker.deleteLater)
        thread.finished.connect(thread.deleteLater)

        # UI-thread callbacks
        worker.log.connect(self.dlg.Log) # safe: runs in UI thread

        def _wrapped_on_finished(result):
            if on_finished:
                if on_finished:
                    sig = inspect.signature(on_finished)
                    if len(sig.parameters) == 0:
                        on_finished()
                    else:
                        if isinstance(result, (tuple, list)):
                            on_finished(*result)
                        else:
                            on_finished(result)
            # Clear current job
            self._bg_thread = None # clear ref
            self._bg_worker = None # clear ref
            # Start next job
            self._start_next_task()

        worker.finished.connect(_wrapped_on_finished)

        # Helpful debug to confirm the signal path
        # thread.started.connect(lambda: self.dlg.Log("QThread.started() emitted"))

        # Start and keep references alive
        self._bg_thread = thread
        self._bg_worker = worker
        thread.start()

class GISPrecip:
    """QGIS Plugin Implementation."""

    def __init__(self, iface):
        """Constructor.

        :param iface: An interface instance that will be passed to this class
            which provides the hook by which you can manipulate the QGIS
            application at run time.
        :type iface: QgsInterface
        """
        # Save reference to the QGIS interface
        self.iface = iface
        # initialize plugin directory
        self.plugin_dir = os.path.dirname(__file__)
        # initialize locale
        locale = QSettings().value('locale/userLocale')[0:2]
        locale_path = os.path.join(
            self.plugin_dir,
            'i18n',
            'GISPrecip_{}.qm'.format(locale))

        if os.path.exists(locale_path):
            self.translator = QTranslator()
            self.translator.load(locale_path)
            QCoreApplication.installTranslator(self.translator)

        # Declare instance attributes
        self.actions = []
        self.menu = self.tr(u'&GISPrecip')

        # Check if plugin was started the first time in current QGIS session
        # Must be set in initGui() to survive plugin reloads
        self.first_start = None

        self.model = None
        self.trained_model_type = None

        self.model_params_layout = None
        self.SVM_degree_param = None
        self.SVM_gamma_param = None
        self.SVM_gamma_value_param = None

        # Thread stuff
        self.is_train_running = False
        self.is_test_running = False
        self.is_predict_running = False
        self.task_queue = None

    # noinspection PyMethodMayBeStatic
    def tr(self, message):
        """Get the translation for a string using Qt translation API.

        We implement this ourselves since we do not inherit QObject.

        :param message: String for translation.
        :type message: str, QString

        :returns: Translated version of message.
        :rtype: QString
        """
        # noinspection PyTypeChecker,PyArgumentList,PyCallByClass
        return QCoreApplication.translate('GISPrecip', message)


    def add_action(
        self,
        icon_path,
        text,
        callback,
        enabled_flag=True,
        add_to_menu=True,
        add_to_toolbar=True,
        status_tip=None,
        whats_this=None,
        parent=None):
        """Add a toolbar icon to the toolbar.

        :param icon_path: Path to the icon for this action. Can be a resource
            path (e.g. ':/plugins/foo/bar.png') or a normal file system path.
        :type icon_path: str

        :param text: Text that should be shown in menu items for this action.
        :type text: str

        :param callback: Function to be called when the action is triggered.
        :type callback: function

        :param enabled_flag: A flag indicating if the action should be enabled
            by default. Defaults to True.
        :type enabled_flag: bool

        :param add_to_menu: Flag indicating whether the action should also
            be added to the menu. Defaults to True.
        :type add_to_menu: bool

        :param add_to_toolbar: Flag indicating whether the action should also
            be added to the toolbar. Defaults to True.
        :type add_to_toolbar: bool

        :param status_tip: Optional text to show in a popup when mouse pointer
            hovers over the action.
        :type status_tip: str

        :param parent: Parent widget for the new action. Defaults None.
        :type parent: QWidget

        :param whats_this: Optional text to show in the status bar when the
            mouse pointer hovers over the action.

        :returns: The action that was created. Note that the action is also
            added to self.actions list.
        :rtype: QAction
        """

        icon = QIcon(icon_path)
        action = QAction(icon, text, parent)
        action.triggered.connect(callback)
        action.setEnabled(enabled_flag)

        if status_tip is not None:
            action.setStatusTip(status_tip)

        if whats_this is not None:
            action.setWhatsThis(whats_this)

        if add_to_toolbar:
            # Adds plugin icon to Plugins toolbar
            self.iface.addToolBarIcon(action)

        if add_to_menu:
            self.iface.addPluginToRasterMenu(
                self.menu,
                action)

        self.actions.append(action)

        return action

    def initGui(self):
        """Create the menu entries and toolbar icons inside the QGIS GUI."""

        icon_path = ':/plugins/GIS_Precip/icon.png'
        self.add_action(
            icon_path,
            text=self.tr(u'GIS Precip'),
            callback=self.run,
            parent=self.iface.mainWindow())

        # will be set False in run()
        self.first_start = True


    def unload(self):
        """Removes the plugin menu item and icon from QGIS GUI."""
        for action in self.actions:
            self.iface.removePluginRasterMenu(
                self.tr(u'&GISPrecip'),
                action)
            self.iface.removeToolBarIcon(action)

        # # Delete the Temp directory if it exists
        # temp_dir = os.path.join(os.getcwd(), 'Temp')
        # if os.path.exists(temp_dir) and os.path.isdir(temp_dir):
        #     import shutil
        #     shutil.rmtree(temp_dir)


    def get_layer_by_name(self, layer_name, idx=0):
        """Get a layer by its name."""
        layers = QgsProject.instance().mapLayersByName(layer_name)
        if layers:
            return layers[idx]
        else:
            return None

    def get_project_or_working_directory(self):
        """Get the project directory (if available) or working directory."""

        # Get the project instance
        project = QgsProject.instance()

        # Get the full path to the project file
        project_filepath = project.fileName()

        # Check if a project is loaded
        if project_filepath:
            # Extract the directory from the project file path
            project_directory = os.path.dirname(project_filepath)
        else:
            # If no project is loaded, use the current working directory
            project_directory = os.getcwd()
        return project_directory

    # Helper function to recursively collect all layers from the layer tree
    def get_all_layers_with_children(self, tree_nodes):
        layers = []
        for node in tree_nodes:
            if hasattr(node, 'layer') and node.layer() is not None:
                layers.append(node.layer())
            elif hasattr(node, 'children'):
                layers.extend(self.get_all_layers_with_children(node.children()))
        return layers

    def get_long_lat(self, layer):
        """Get longitude and latitude from the layer."""
        # This method will be implemented to extract longitudes and latitudes
        self.dlg.Log("Extracting longitude and latitude from layer: {}".format(layer.name()))

        # Assuming the layer has a CRS with geographic coordinates
        crs = layer.crs()
        if crs.isGeographic():
            extent = layer.extent()
            long = np.linspace(extent.xMinimum(), extent.xMaximum(), layer.width())
            lat = np.linspace(extent.yMinimum(), extent.yMaximum(), layer.height())
            self.dlg.Log("Longitude and latitude extracted successfully.")
            return long, lat
        else:
            self.dlg.Log("Layer CRS is not geographic. Cannot extract longitude and latitude.")
            return None, None

    def get_gmi_data(self, gmi_layer):
        """Preprocess GMI data layer."""
        # This method will be implemented to preprocess GMI data
        self.dlg.Log("Preprocessing GMI data layer: {}".format(gmi_layer.name()))

        mask = True
        arr = gmi_layer.as_numpy(mask)  # 13 bands, size is (bands, lat, long) -> (bands, width, height)
        long, lat = self.get_long_lat(gmi_layer)

        # Create a grid of coordinates
        long_coords, lat_coords = np.meshgrid(long, lat, indexing='ij')

        # Flatten everything
        long_flat = long_coords.flatten()
        lat_flat = lat_coords.flatten()
        data_flat = arr.reshape(13, -1).T  # shape (width*height, bands)

        # # Concatenate
        # output = np.column_stack((x_flat, y_flat, data_flat))  # shape (width*height, (long,lat,bands))

        self.dlg.Log("GMI data preprocessing completed for layer: {}".format(gmi_layer.name()))
        return data_flat, long_flat, lat_flat

    def get_surf_precip_data(self, surf_precip_layer):
        """Preprocess surface precipitation data layer."""
        # This method will be implemented to preprocess surface precipitation data
        self.dlg.Log("Preprocessing surface precipitation data layer: {}".format(surf_precip_layer.name()))

        mask = True
        arr = surf_precip_layer.as_numpy(mask) # size is (surface_precip, lat, long) -> (surface_precip, width, height)
        long, lat = self.get_long_lat(surf_precip_layer)

        # Create a grid of coordinates
        long_coords, lat_coords = np.meshgrid(long, lat, indexing='ij')

        # Flatten everything
        long_flat = long_coords.flatten()
        lat_flat = lat_coords.flatten()
        data_flat = arr.reshape(1, -1).T.flatten()  # shape (width*height, surface_precip)

        # # Concatenate
        # output = np.column_stack((x_flat, y_flat, data_flat))  # shape (width*height, (long,lat,surface_precip))

        self.dlg.Log("Surface precipitation data preprocessing completed for layer: {}".format(surf_precip_layer.name()))
        return data_flat, long_flat, lat_flat

    def convert_to_classification(self, surf_precip_data):
        # if model_name == "SVM":
        #     # Convert precipitation to binary label (rain/no rain)
        #     self.dlg.Log("Creating precipitation intensity binary classes (0: No rain, 1: Rain)")
        #     return (surf_precip_data > 0.1).astype(int)  # 0 = no rain, 1 = rain
        # else:
        # TODO: QGIS maps the data to colors based on min and max values, not based on the classes defined here
        self.dlg.Log("Creating precipitation intensity classes (0: No rain, 1: Light, 2: Moderate, 3: Heavy, 4: Violent)")
        y = surf_precip_data.flatten()
        cat = np.zeros_like(y, dtype=int)
        cat[(y > 0.0) & (y < 2.5)] = 1  # Leve
        cat[(y >= 2.5) & (y < 10)] = 2  # Moderada
        cat[(y >= 10) & (y < 50)] = 3  # Pesada
        cat[(y >= 50)] = 4 # Violenta
        return cat

    def preprocess_data(self, gmi_data, surf_precip_data, long, lat, under_sample=False):
        """Preprocess the GMI and surface precipitation data."""
        self.dlg.Log("Preprocessing GMI and surface precipitation data...")

        # Check if the data is valid
        mask = np.isfinite(gmi_data).all(axis=1) & np.isfinite(surf_precip_data).flatten()
        # mask = np.isfinite(surf_precip_data) & np.all(np.isfinite(gmi_data), axis=1)
        # Check if the data is masked
        if np.ma.isMaskedArray(gmi_data):
            mask &= ~np.ma.getmaskarray(gmi_data).any(axis=1)
        if np.ma.isMaskedArray(surf_precip_data):
            mask &= ~np.ma.getmaskarray(surf_precip_data).flatten()
        # Remove invalid samples
        gmi_data = gmi_data[mask]
        surf_precip_data = surf_precip_data[mask]
        long = long[mask]
        lat = lat[mask]

        if self.trained_model_type == "Classification":
            surf_precip_data = self.convert_to_classification(surf_precip_data)

        if self.trained_model_type == "Classification":
            # if under_sample and model_name == "SVM": # This seems to be the only model that needs under-sampling
            if under_sample:
                # Handle class imbalance using RandomUnderSampler
                gmi_data, surf_precip_data = RandomUnderSampler(random_state=42).fit_resample(gmi_data, surf_precip_data)

        self.dlg.Log("Data preprocessing completed.")
        return gmi_data, surf_precip_data, long, lat

    def preprocess_data_test(self, gmi_data, surf_precip_data, long, lat):
        """Preprocess the GMI and surface precipitation data."""
        self.dlg.Log("Preprocessing GMI and surface precipitation data...")

        # Check if the data is valid
        mask = np.isfinite(gmi_data).all(axis=1) & np.isfinite(surf_precip_data).flatten()
        # mask = np.isfinite(surf_precip_data) & np.all(np.isfinite(gmi_data), axis=1)
        # Check if the data is masked
        if np.ma.isMaskedArray(gmi_data):
            mask &= ~np.ma.getmaskarray(gmi_data).any(axis=1)
        if np.ma.isMaskedArray(surf_precip_data):
            mask &= ~np.ma.getmaskarray(surf_precip_data).flatten()
        # Remove invalid samples
        gmi_data = gmi_data[mask]
        surf_precip_data = surf_precip_data[mask]
        long = long[mask]
        lat = lat[mask]

        if self.trained_model_type == "Classification":
            surf_precip_data = self.convert_to_classification(surf_precip_data)

        self.dlg.Log("Data preprocessing completed.")
        return gmi_data, surf_precip_data, long, lat, mask

    def preprocess_GMI_data(self, gmi_data, long, lat):
        """Preprocess the GMI and surface precipitation data."""
        self.dlg.Log("Preprocessing GMI data...")

        # Check if the data is valid
        mask = np.isfinite(gmi_data).all(axis=1)
        # Check if the data is masked
        if np.ma.isMaskedArray(gmi_data):
            mask &= ~np.ma.getmaskarray(gmi_data).any(axis=1)
        # Remove invalid samples
        gmi_data = gmi_data[mask]
        long = long[mask]
        lat = lat[mask]

        self.dlg.Log("Data preprocessing completed.")
        return gmi_data, long, lat, mask

    def get_model_type(self, model):
        if model == 'MLP Regressor':
            return "Regression"
        elif model == 'SVM':
            return "Classification"
        elif model == 'Random Forest':
            return "Classification"
        elif model == 'Decision Tree':
            return "Classification"
        elif model == 'AdaBoost':
            return "Classification"
        else:
            return "None"
        
    def save_model(self):
        filepath = self.dlg.fileWidget_ExportModel.lineEdit().value()

        # Bundle everything into a dict
        package = {
            "model": self.model,
            "extra_data": {
                "type": self.trained_model_type
            }
        }

        try:
            with open(filepath, 'wb') as f:
                pickle.dump(package, f)
                self.dlg.Log("Model saved to {}".format(filepath))
        except Exception as e:
            self.dlg.Log("Failed to save model to {}: {}".format(filepath, e))

    def load_model(self):
        filepath = self.dlg.fileWidget_LoadModel.lineEdit().value()
        try:
            with open(filepath, 'rb') as f:
                package = pickle.load(f)
                self.model = package.get("model")
                self.trained_model_type = package.get("extra_data", {}).get("type")
                self.dlg.Log("Model loaded from {}".format(filepath))
        except Exception as e:
            self.dlg.Log("Failed to load model from {}: {}".format(filepath, e))

    def get_model_metrics_reg(self, y_true, y_pred):
        """Calculate model metrics."""
        self.dlg.Log("Calculating model metrics...")

        bias = np.mean(y_pred - y_true)
        mse = mean_squared_error(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)

        def smape(y_true, y_pred):
            # return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))
            return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))

        smape_value = smape(y_true, y_pred)
        lin_corr = np.corrcoef(y_true, y_pred)[0, 1]

        self.dlg.Log("Model metrics calculated.")
        return bias, mse, mae, smape_value, lin_corr


    def export_to_netCDF4_file(self, width, height, long, lat, mask, data, output_filepath):

        # Create the output directory if it does not exist
        output_dir = os.path.dirname(output_filepath)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # Remove existing layer with the same name if it exists
        layer_name = Path(output_filepath).stem
        existing_layer = self.get_layer_by_name(layer_name)
        if existing_layer:
            QgsProject.instance().removeMapLayer(existing_layer.id())

        ncfile = Dataset(output_filepath, 'w', format='NETCDF4_CLASSIC')

        # Create dimensions
        lat_dim = ncfile.createDimension('lat', height) # latitude axis
        lon_dim = ncfile.createDimension('lon', width) # longitude axis

        # Create variables
        lat_var = ncfile.createVariable('lat', np.float32, ('lat',))
        lat_var.units = 'degrees'
        lat_var.long_name = 'Latitude'
        lon_var = ncfile.createVariable('lon', np.float32, ('lon',))
        lon_var.units = 'degrees'
        lon_var.long_name = 'Longitude'
        surf_precip = ncfile.createVariable('surface_precip', np.float32, ('lat', 'lon',))
        surf_precip.units = 'mm/h'
        surf_precip.long_name = 'Surface Precipitation'

        # Fill into full grid with NaNs
        y_pred_map = np.full(mask.shape, np.nan)

        y_pred_map[mask] = data

        y_pred_map = y_pred_map.reshape(width, height)

        # Write latitudes, longitudes.
        # Note: the ":" is necessary in these "write" statements
        lat_var[:] = lat
        lon_var[:] = long
        # Write the data.  This writes the whole 3D netCDF variable all at once.
        surf_precip[:, :] = y_pred_map[::-1, :]
        # self.dlg.Log("-- Wrote data, temp.shape is now {}".format(surf_precip.shape))
        # # read data back from variable (by slicing it), print min and max
        # self.dlg.Log("-- Min/Max values: {}/{}".format(surf_precip[:, :].min(), surf_precip[:, :].max()))

        # Log the output netCDF4 file
        # self.dlg.Log(ncfile)

        # close the Dataset.
        ncfile.close()

        # Load the exported netCDF4 file as a raster layer
        raster_layer = QgsRasterLayer(output_filepath, layer_name)
        raster_layer.setCrs(QgsProject.instance().crs())
        # Set singleband pseudocolor renderer
        raster_layer.setRenderer(QgsSingleBandPseudoColorRendererWidget(raster_layer).renderer())
        if not raster_layer.isValid():
            self.dlg.Log("Layer failed to load!")
        else:
            QgsProject.instance().addMapLayer(raster_layer)

    def train_model(self):
        """Train the model with the selected GMI and Surface Precipitation data."""
        # This method is implemented to train the model

        # Early out if already training a model
        if self.is_train_running:
            self.dlg.Log("Model training is already in progress.")
            return
        self.is_train_running = True

        self.dlg.Log("Training model with selected GMI and Surface Precipitation data...")

        self.dlg.progressBar_TrainModel.setRange(0, 0)
        self.dlg.progressBar_TrainModel.setValue(0)

        # Fetch the currently loaded layers
        layers = QgsProject.instance().layerTreeRoot().children()

        # Collect selected GMI layers
        checkedLayers_GMI = self.dlg.comboBox_InputGMI.checkedItems()
        checkedLayers_SurfPrecip = self.dlg.comboBox_InputSurfPrecip.checkedItems()

        gmi_data_list, surf_precip_list, long_list, lat_list = [], [], [], []

        model_name = self.dlg.comboBox_InputModel.currentText()
        self.trained_model_type = self.get_model_type(model_name) # this must be before preprocessing the data, since it is used there

        # Process each GMI and surface precipitation layer as a pair
        for gmi_name, precip_name in zip(checkedLayers_GMI, checkedLayers_SurfPrecip):
            selectedLayer_GMI = self.get_layer_by_name(gmi_name)
            selectedLayer_SurfPrecip = self.get_layer_by_name(precip_name)
            bands, long, lat = self.get_gmi_data(selectedLayer_GMI)
            surfPrecip, _, _ = self.get_surf_precip_data(selectedLayer_SurfPrecip)

            # ====== FILTRO DE QUALIDADE ======
            # surfPrecip, rqi, _ = self.get_surf_precip_data(selectedLayer_SurfPrecip)
            # min_rqi_threshold = 0.0
            # mask_valid = (rqi >= min_rqi_threshold)

            # Aplica mÃ¡scara: NaN para valores ruins
            # surfPrecip = np.where(mask_valid, surfPrecip, np.nan)

            # ====== TRATAMENTO DE NAN ======
            # nan_fill_value = -1.5
            # bands = np.where(np.isnan(bands), nan_fill_value, bands)
            # surfPrecip = np.where(np.isnan(surfPrecip), nan_fill_value, surfPrecip)
            # ===============================

            gmi_data_list.append(bands)
            surf_precip_list.append(surfPrecip)
            long_list.append(long)
            lat_list.append(lat)

        # Concatenate all data (masked)
        bands = np.ma.concatenate(gmi_data_list, axis=0)
        long = np.ma.concatenate(long_list, axis=0)
        lat = np.ma.concatenate(lat_list, axis=0)
        surfPrecip = np.ma.concatenate(surf_precip_list, axis=0)

        # Preprocess the data
        undersampling = self.dlg.checkBox_Undersampling.isChecked()
        bands, surfPrecip, long, lat = self.preprocess_data(bands, surfPrecip, long, lat, under_sample=undersampling)

        # Create and train the SVM model
        if self.dlg.checkBox_Normalize.isChecked():
            if model_name == "MLP Regressor":
                from sklearn.preprocessing import MinMaxScaler
                scaler_step = ('scaler', MinMaxScaler())
            else:
                from sklearn.preprocessing import StandardScaler
                scaler_step = ('scaler', StandardScaler())
        else:
            scaler_step = None
        # scaler_step = ('scaler', RobustScaler()) if normalizer else None
        model_step = None
        if model_name == "MLP Regressor":
            # Convert a string like '20;20' to a tuple like (20, 20)
            hid_layers_str = self.model_params_layout.itemAt(1, 1).widget().text()
            hidden_layer_sizes = tuple(int(x) for x in hid_layers_str.split(';') if x.strip())
            model_step = ('mlp', MLPRegressor(
                activation=self.model_params_layout.itemAt(0, 1).widget().currentText(),
                hidden_layer_sizes=hidden_layer_sizes,
                alpha=0.0011045192633616075,
                learning_rate_init=self.model_params_layout.itemAt(2, 1).widget().value(),
                solver=self.model_params_layout.itemAt(3, 1).widget().currentText(),
                max_iter=self.model_params_layout.itemAt(4, 1).widget().value(),
                early_stopping=True,
                n_iter_no_change=10,
                validation_fraction=0.1,
                shuffle=True,
                random_state=self.model_params_layout.itemAt(5, 1).widget().value()
            ))
        elif model_name == "SVM":
            degree_param = 3 if self.SVM_degree_param is None else self.SVM_degree_param.value()
            gamma_param = 'scale' if self.SVM_gamma_param is None else self.SVM_gamma_param.currentText()
            if gamma_param == 'float':
                gamma_param = self.SVM_gamma_value_param.value()
            model_step = ('svm', SVC(
                kernel=self.model_params_layout.itemAt(0, 1).widget().currentText(),
                C=self.model_params_layout.itemAt(1, 1).widget().value(),
                degree=degree_param,
                gamma=gamma_param,
                class_weight='balanced', # use balanced weights if rain is rare
                decision_function_shape=self.model_params_layout.itemAt(2, 1).widget().currentText(),
                random_state=self.model_params_layout.itemAt(3, 1).widget().value()))
        elif model_name == "Random Forest":
            model_step = ('rf', RandomForestClassifier(
                n_estimators=self.model_params_layout.itemAt(0, 1).widget().value(),
                criterion=self.model_params_layout.itemAt(1, 1).widget().currentText(),
                min_samples_split=self.model_params_layout.itemAt(2, 1).widget().value(),
                min_impurity_decrease=self.model_params_layout.itemAt(3, 1).widget().value(),
                random_state=self.model_params_layout.itemAt(4, 1).widget().value(),
                class_weight='balanced'))
        elif model_name == "Decision Tree":
            model_step = ('dt', DecisionTreeClassifier(
                criterion=self.model_params_layout.itemAt(0, 1).widget().currentText(),
                splitter=self.model_params_layout.itemAt(1, 1).widget().currentText(),
                min_samples_split=self.model_params_layout.itemAt(2, 1).widget().value(),
                min_impurity_decrease=self.model_params_layout.itemAt(3, 1).widget().value(),
                random_state=self.model_params_layout.itemAt(4, 1).widget().value(),
                class_weight='balanced'))
        elif model_name == "AdaBoost":
            estimator = self.model_params_layout.itemAt(0, 1).widget().currentText()
            if estimator == "Decision Tree":
                estimator = DecisionTreeClassifier()
            model_step = ('ada', AdaBoostClassifier(
                estimator=estimator,
                n_estimators=self.model_params_layout.itemAt(1, 1).widget().value(),
                learning_rate=self.model_params_layout.itemAt(2, 1).widget().value(),
                random_state=self.model_params_layout.itemAt(3, 1).widget().value()))
        self.model = Pipeline([scaler_step, model_step])
        self.trained_model_type = self.get_model_type(model_name)
        # Run model training asynchronously to avoid blocking the UI

        def train_model_fn(bands, surfPrecip):
            self.model.fit(bands, surfPrecip)

        def on_training_finished():
            self.dlg.progressBar_TrainModel.setRange(0, 100)
            self.dlg.progressBar_TrainModel.setValue(100)
            self.dlg.Log("Model training completed.")
            self.is_train_running = False
            self.dlg.button_ExportModel.setEnabled(True)

        self.dlg.progressBar_TrainModel.setValue(10)
        self.dlg.Log("Training model asynchronously...")

        self.task_queue.add_task(train_model_fn, bands, surfPrecip, on_finished=on_training_finished)

    def test_model(self):
        """Test the model with the selected GMI and Surface Precipitation data."""
        # This method is implemented to test the model

        # Early out if already testing a model
        if self.is_test_running:
            self.dlg.Log("Model testing is already in progress.")
            return
        self.is_test_running = True

        self.dlg.Log("Testing model with selected GMI and Surface Precipitation data...")

        self.dlg.progressBar_RunTest.setValue(0)

        # Fetch the currently loaded layers
        layers = QgsProject.instance().layerTreeRoot().children()

        # Collect selected GMI layers
        checkedLayers_GMI = self.dlg.comboBox_TestGMI.checkedItems()
        checkedLayers_SurfPrecip = self.dlg.comboBox_TestSurfPrecip.checkedItems()

        # Collect all true and predicted values for global metrics
        all_y_true = []
        all_y_pred = []

        # Process each GMI and surface precipitation layer as a pair
        total_tests = len(checkedLayers_GMI)
        for idx, (gmi_name, precip_name) in enumerate(zip(checkedLayers_GMI, checkedLayers_SurfPrecip), start=1):
            # Update progress bar percentage for each test
            percent_complete = int((idx / total_tests) * 100) if total_tests > 0 else 0
    
            selectedLayer_GMI = self.get_layer_by_name(gmi_name)
            bands, long, lat = self.get_gmi_data(selectedLayer_GMI)
            selectedLayer_SurfPrecip = self.get_layer_by_name(precip_name)
            surfPrecip, _, _ = self.get_surf_precip_data(selectedLayer_SurfPrecip)

            # Preprocess the data
            bands, surfPrecip, long, lat, mask = self.preprocess_data_test(bands, surfPrecip, long, lat)

            def test_model_fn(bands, surfPrecip, mask, precip_name, selectedLayer_GMI, percent_complete):
                # Evaluate the model
                y_pred = self.model.predict(bands)
                return y_pred, surfPrecip, mask, precip_name, selectedLayer_GMI, percent_complete

            def on_testing_finished(y_pred, surfPrecip, mask, precip_name, selectedLayer_GMI, percent_complete):
                # Manual clip for regression since scikit-learn does not allow to change the output activation function
                if self.trained_model_type == "Regression":
                    y_pred = np.maximum(0, y_pred)

                # Collect for global metrics
                all_y_true.append(surfPrecip.flatten())
                all_y_pred.append(y_pred.flatten())

                # Export the results to a netCDF4 file and load it as a raster layer
                long_width, lat_height = self.get_long_lat(selectedLayer_GMI)
                out_dir = self.dlg.fileWidget_TestOutput.lineEdit().value()
                if not out_dir:
                    out_dir = os.path.join(os.getcwd(), 'Temp')
                safe_precip_name = re.sub(r'[^\w\-]', '_', precip_name)
                filepath = os.path.join(out_dir, f'test_{safe_precip_name}.nc')
                self.dlg.Log("Writing test output to file %s..." % filepath)
                self.export_to_netCDF4_file(len(long_width), len(lat_height), long_width, lat_height, mask, y_pred, filepath)

                self.dlg.progressBar_RunTest.setValue(percent_complete)


            self.task_queue.add_task(test_model_fn, bands, surfPrecip, mask, precip_name, selectedLayer_GMI, percent_complete, on_finished=on_testing_finished)

        def test_dummy_fn():
            pass

        def on_test_dummy_finished():
            # After the loop, concatenate all values and calculate metrics once
            y_true_global = np.concatenate(all_y_true)
            y_pred_global = np.concatenate(all_y_pred)

            classes = [0, 1, 2, 3, 4]
            if self.trained_model_type == "Classification":
                # Hides the regression metrics table and show classification tables
                self.display_metrics_tables(["Classification"])

                # self.dlg.Log("Global model evaluation:")

                # self.dlg.Log(classification_report(y_true_global, y_pred_global))

                report = classification_report(y_true_global, y_pred_global, output_dict=True)

                # Loop for each class in classes and get each metric this way
                for i, cls in enumerate(classes):
                    cls_str = str(cls)
                    metrics = report.get(cls_str, {})
                    for j, metric_name in enumerate(["precision", "recall", "f1-score", "support"]):
                        value = metrics.get(metric_name, 0.0)
                        if value is not None:
                            if metric_name == "support":
                                self.dlg.tableWidget_MetricsClassification.setItem(i, j, QTableWidgetItem(f"{int(value)}"))
                            else:
                                self.dlg.tableWidget_MetricsClassification.setItem(i, j, QTableWidgetItem(f"{value:.4f}"))

                # Accuracy, macro avg, weighted avg
                accuracy = report.get("accuracy", 0.0)
                accuracy_support = sum(report[str(cls)]["support"] for cls in classes if str(cls) in report)
                self.dlg.tableWidget_MetricsClassification.setItem(len(classes), 3, QTableWidgetItem(f"{int(accuracy_support)}"))
                self.dlg.tableWidget_MetricsClassification.setItem(len(classes), 4, QTableWidgetItem(f"{accuracy:.4f}"))
                macro_avg = report.get("macro avg", {})
                for i, metric in enumerate(["precision", "recall", "f1-score", "support"]):
                    value = macro_avg.get(metric, 0.0)
                    if value is not None:
                        if metric == "support":
                            self.dlg.tableWidget_MetricsClassification.setItem(len(classes) + 1, i, QTableWidgetItem(f"{int(value)}"))
                        else:
                            self.dlg.tableWidget_MetricsClassification.setItem(len(classes) + 1, i, QTableWidgetItem(f"{value:.4f}"))
                weighted_avg = report.get("weighted avg", {})
                for i, metric in enumerate(["precision", "recall", "f1-score", "support"]):
                    value = weighted_avg.get(metric, 0.0)
                    if value is not None:
                        if metric == "support":
                            self.dlg.tableWidget_MetricsClassification.setItem(len(classes) + 2, i, QTableWidgetItem(f"{int(value)}"))
                        else:
                            self.dlg.tableWidget_MetricsClassification.setItem(len(classes) + 2, i, QTableWidgetItem(f"{value:.4f}"))

                # Confusion matrix
                cm = confusion_matrix(y_true_global, y_pred_global)
                # Iterate through the confusion matrix
                # Fill the confusion matrix table with actual values
                for i, row in enumerate(cm):
                    for j, value in enumerate(row):
                        self.dlg.tableWidget_ConfusionMatrixClassification.setItem(i, j, QTableWidgetItem(f"{int(value)}"))
                # Set all other elements to zero
                row_count = self.dlg.tableWidget_ConfusionMatrixClassification.rowCount()
                col_count = self.dlg.tableWidget_ConfusionMatrixClassification.columnCount()
                for i in range(row_count):
                    for j in range(col_count):
                        if i >= len(cm) or j >= len(cm[i]):
                            self.dlg.tableWidget_ConfusionMatrixClassification.setItem(i, j, QTableWidgetItem("0"))

                # self.dlg.Log("Global Confusion Matrix:")
                # self.dlg.Log(cm)
        
            elif self.trained_model_type == "Regression":
                # Shows the regression metrics table and hide classification tables
                self.display_metrics_tables(["Regression"])

                bias, mse, mae, smape_value, lin_corr = self.get_model_metrics_reg(y_true_global, y_pred_global)

                # Update the table with model metrics
                self.dlg.tableWidget_ModelMetrics.setItem(0, 0, QTableWidgetItem(f"{bias:.4f}"))
                self.dlg.tableWidget_ModelMetrics.setItem(0, 1, QTableWidgetItem(f"{mse:.4f}"))
                self.dlg.tableWidget_ModelMetrics.setItem(0, 2, QTableWidgetItem(f"{mae:.4f}"))
                self.dlg.tableWidget_ModelMetrics.setItem(0, 3, QTableWidgetItem(f"{smape_value:.4f}"))
                self.dlg.tableWidget_ModelMetrics.setItem(0, 4, QTableWidgetItem(f"{lin_corr:.4f}"))

            # Log the testing completion
            self.dlg.progressBar_RunTest.setValue(100)
            self.dlg.Log("Model testing completed.")
            self.is_test_running = False

        self.task_queue.add_task(test_dummy_fn, on_finished=on_test_dummy_finished)


    def predict_model(self):
        """Test the model with the selected GMI data."""
        # This method is implemented to predict the model

        # Early out if already predicting a model
        if self.is_predict_running:
            self.dlg.Log("Model prediction is already in progress.")
            return
        self.is_predict_running = True

        self.dlg.Log("Predicting model with selected GMI data...")

        # Fetch the currently loaded layers
        layers = QgsProject.instance().layerTreeRoot().children()

        # Collect selected GMI layers
        checkedLayers_GMI = self.dlg.comboBox_ForecastGMI.checkedItems()

        # Process each GMI layer
        total_tests = len(checkedLayers_GMI)
        for idx, (gmi_name) in enumerate(checkedLayers_GMI, start=1):
            # Update progress bar percentage for each test
            percent_complete = int((idx / total_tests) * 100) if total_tests > 0 else 0

            selectedLayer_GMI = self.get_layer_by_name(gmi_name)
            bands, long, lat = self.get_gmi_data(selectedLayer_GMI)

            # Preprocess the data
            bands, long, lat, mask = self.preprocess_GMI_data(bands, long, lat)

            def predict_model_fn(bands, mask, gmi_name, selectedLayer_GMI, percent_complete):
                # Evaluate the model
                y_pred = self.model.predict(bands)
                return y_pred, mask, gmi_name, selectedLayer_GMI, percent_complete

            def on_predicting_finished(y_pred, mask, gmi_name, selectedLayer_GMI, percent_complete):
                # Manual clip for regression since scikit-learn does not allow to change the output activation function
                model_name = self.dlg.comboBox_InputModel.currentText()
                if self.get_model_type(model_name) == "Regression":
                    y_pred = np.maximum(0, y_pred)

                # Export the results to a netCDF4 file and load it as a raster layer
                long_width, lat_height = self.get_long_lat(selectedLayer_GMI)
                out_dir = self.dlg.fileWidget_ForecastOutput.lineEdit().value()
                if not out_dir:
                    out_dir = os.path.join(os.getcwd(), 'Temp')
                safe_gmi_name = re.sub(r'[^\w\-]', '_', gmi_name)
                filepath = os.path.join(out_dir, f'predict_{safe_gmi_name}.nc')
                self.dlg.Log("Writing predict output to file %s..." % filepath)
                self.export_to_netCDF4_file(len(long_width), len(lat_height), long_width, lat_height, mask, y_pred, filepath)

                self.dlg.progressBar_Predict.setValue(percent_complete)

            self.task_queue.add_task(predict_model_fn, bands, mask, gmi_name, selectedLayer_GMI, percent_complete, on_finished=on_predicting_finished)

        def predict_dummy_fn():
            pass

        def on_predict_dummy_finished():
            # Log the prediction completion
            self.dlg.progressBar_Predict.setValue(100)
            self.dlg.Log("Model prediction completed.")
            self.is_predict_running = False

        self.task_queue.add_task(predict_dummy_fn, on_finished=on_predict_dummy_finished)


    def on_svm_kernel_gamma_changed(self, value, gamma_row):
        """Handle changes in the SVM kernel gamma parameter."""
        self.model_params_layout.removeRow(gamma_row)
        if value == "float":
            self.SVM_gamma_value_param = QDoubleSpinBox()
            self.SVM_gamma_value_param.setDecimals(6)
            self.SVM_gamma_value_param.setRange(0.000001, 10000.0)
            self.SVM_gamma_value_param.setSingleStep(0.1)
            self.SVM_gamma_value_param.setValue(0.5)
            self.model_params_layout.insertRow(gamma_row, 'Gamma value:', self.SVM_gamma_value_param)

    def on_svm_kernel_changed(self, value):
        """Handle changes in the SVM kernel parameter."""
        self.model_params_layout.removeRow(6)
        self.model_params_layout.removeRow(5)
        self.model_params_layout.removeRow(4)
        if value == "poly":
            self.SVM_degree_param = QSpinBox()
            self.SVM_degree_param.setRange(0, 50)
            self.SVM_degree_param.setValue(3)
            self.model_params_layout.insertRow(4, 'Degree:', self.SVM_degree_param)
        if value == "rbf" or value == "poly" or value == "sigmoid":
            self.SVM_gamma_param = QComboBox()
            self.SVM_gamma_param.addItems(["scale", "auto", "float"])
            self.SVM_gamma_param.setCurrentText("scale")
            self.SVM_gamma_param.currentTextChanged.connect(lambda value: self.on_svm_kernel_gamma_changed(value, gamma_row))
            gamma_row = 0
            if value == "poly": gamma_row = 6
            else: gamma_row = 5
            self.model_params_layout.insertRow(gamma_row, 'Gamma:', self.SVM_gamma_param)

    def on_model_changed(self, cur_model):
        """Handle changes in the model selection."""
        self.dlg.formLayout_Model.removeRow(self.model_params_layout)

        self.model_params_layout = QFormLayout()

        if cur_model == "MLP Regressor":
            activation_functions = QComboBox()
            activation_functions.addItems(["identity", "logistic", "tanh", "relu"])
            activation_functions.setCurrentText("relu")
            hid_layers_neurons = QLineEdit()
            hid_layers_neurons.setText('20;20')
            hid_layers_neurons.setValidator(QRegExpValidator(QRegExp(r'^\d+(;\d+)*$')))
            hid_layers_neurons.setToolTip("Enter hidden layer sizes as 'neurons1;neurons2;...'")
            learning_rate = QDoubleSpinBox()
            learning_rate.setDecimals(6)
            learning_rate.setRange(0.000001, 10.0)
            learning_rate.setSingleStep(0.001)
            learning_rate.setValue(0.001)
            solver_options = QComboBox()
            solver_options.addItems(["adam", "sgd"])
            solver_options.setCurrentText("adam")
            max_epochs = QSpinBox()
            max_epochs.setRange(1, 100000)
            max_epochs.setValue(500)
            random_seed = QSpinBox()
            random_seed.setRange(0, 1000000)
            random_seed.setValue(8)
            self.model_params_layout.insertRow(0, 'Activation Function:', activation_functions)
            self.model_params_layout.insertRow(1, 'Hidden Layers Neurons:', hid_layers_neurons)
            self.model_params_layout.insertRow(2, 'Learning Rate:', learning_rate)
            self.model_params_layout.insertRow(3, 'Solver:', solver_options)
            self.model_params_layout.insertRow(4, 'Max Epochs:', max_epochs)
            self.model_params_layout.insertRow(5, 'Random Seed:', random_seed)

        elif cur_model == "SVM":
            kernel = QComboBox()
            kernel.addItems(["rbf", "linear", "poly", "sigmoid"])
            kernel.currentTextChanged.connect(self.on_svm_kernel_changed)
            kernel.setCurrentText("rbf")
            self.on_svm_kernel_changed("rbf")
            C_param = QDoubleSpinBox()
            C_param.setDecimals(6)
            C_param.setRange(0.000001, 100000.0)
            C_param.setSingleStep(1.0)
            C_param.setValue(100.0)
            decision_type = QComboBox()
            decision_type.addItems(["ovr", "ovo"])
            decision_type.setCurrentText("ovr")
            random_seed = QSpinBox()
            random_seed.setRange(0, 1000000)
            random_seed.setValue(8)
            self.model_params_layout.insertRow(0, 'Kernel:', kernel)
            self.model_params_layout.insertRow(1, 'C:', C_param)
            self.model_params_layout.insertRow(2, 'Decision Type:', decision_type)
            self.model_params_layout.insertRow(3, 'Random Seed:', random_seed)

        elif cur_model == "Random Forest":
            n_estimators = QSpinBox()
            n_estimators.setRange(1, 1000000)
            n_estimators.setSingleStep(1)
            n_estimators.setValue(100)
            criterion = QComboBox()
            criterion.addItems(["gini", "entropy", "log_loss"])
            criterion.setCurrentText("entropy")
            min_samples_split = QSpinBox()
            min_samples_split.setRange(0, 1000000)
            min_samples_split.setSingleStep(1)
            min_samples_split.setValue(10)
            min_impurity_decrease = QDoubleSpinBox()
            min_impurity_decrease.setDecimals(15)
            min_impurity_decrease.setRange(0.0, 100000.0)
            min_impurity_decrease.setSingleStep(0.000001)
            min_impurity_decrease.setValue(1e-6)
            random_seed = QSpinBox()
            random_seed.setRange(0, 1000000)
            random_seed.setValue(8)
            self.model_params_layout.insertRow(0, 'Number of Trees:', n_estimators)
            self.model_params_layout.insertRow(1, 'Criterion:', criterion)
            self.model_params_layout.insertRow(2, 'Min Samples Split:', min_samples_split)
            self.model_params_layout.insertRow(3, 'Min Impurity Decrease:', min_impurity_decrease)
            self.model_params_layout.insertRow(4, 'Random Seed:', random_seed)

        elif cur_model == "Decision Tree":
            criterion = QComboBox()
            criterion.addItems(["gini", "entropy", "log_loss"])
            criterion.setCurrentText("entropy")
            splitter = QComboBox()
            splitter.addItems(["best", "random"])
            splitter.setCurrentText("best")
            min_samples_split = QSpinBox()
            min_samples_split.setRange(0, 1000000)
            min_samples_split.setSingleStep(1)
            min_samples_split.setValue(10)
            min_impurity_decrease = QDoubleSpinBox()
            min_impurity_decrease.setDecimals(15)
            min_impurity_decrease.setRange(0.0, 100000.0)
            min_impurity_decrease.setSingleStep(0.000001)
            min_impurity_decrease.setValue(1e-6)
            random_seed = QSpinBox()
            random_seed.setRange(0, 1000000)
            random_seed.setValue(8)
            self.model_params_layout.insertRow(0, 'Criterion:', criterion)
            self.model_params_layout.insertRow(1, 'Splitter:', splitter)
            self.model_params_layout.insertRow(2, 'Min Samples Split:', min_samples_split)
            self.model_params_layout.insertRow(3, 'Min Impurity Decrease:', min_impurity_decrease)
            self.model_params_layout.insertRow(4, 'Random Seed:', random_seed)

        elif cur_model == "AdaBoost":
            estimator = QComboBox()
            estimator.addItems(["Decision Tree"])
            estimator.setCurrentText("Decision Tree")
            n_estimators = QSpinBox()
            n_estimators.setRange(1, 1000000)
            n_estimators.setSingleStep(1)
            n_estimators.setValue(100)
            learning_rate = QDoubleSpinBox()
            learning_rate.setDecimals(6)
            learning_rate.setRange(0.000001, 10.0)
            learning_rate.setSingleStep(0.001)
            learning_rate.setValue(0.001)
            random_seed = QSpinBox()
            random_seed.setRange(0, 1000000)
            random_seed.setValue(8)
            self.model_params_layout.insertRow(0, 'Estimator:', estimator)
            self.model_params_layout.insertRow(1, 'Max Number of Estimators:', n_estimators)
            self.model_params_layout.insertRow(2, 'Learning Rate:', learning_rate)
            self.model_params_layout.insertRow(3, 'Random Seed:', random_seed)

        self.dlg.formLayout_Model.insertRow(3, 'Model Parameters:' ,self.model_params_layout)

        return
    
    def display_metrics_tables(self, metrics_type = []):
        if "Regression" in metrics_type:
            self.dlg.tableWidget_ModelMetrics.show()
        else:
            self.dlg.tableWidget_ModelMetrics.hide()
        if "Classification" in metrics_type:
            self.dlg.tableWidget_MetricsClassification.show()
            self.dlg.label_ConfusionMatrixActual.show()
            self.dlg.label_ConfusionMatrixPredicted.show()
            self.dlg.tableWidget_ConfusionMatrixClassification.show()
        else:
            self.dlg.tableWidget_MetricsClassification.hide()
            self.dlg.label_ConfusionMatrixActual.hide()
            self.dlg.label_ConfusionMatrixPredicted.hide()
            self.dlg.tableWidget_ConfusionMatrixClassification.hide()

    def run(self):
        """Run method that performs all the real work"""

        # Create the dialog with elements (after translation) and keep reference
        # Only create GUI ONCE in callback, so that it will only load when the plugin is started
        if self.first_start == True:
            self.first_start = False
            self.dlg = GISPrecipDialog()
            self.dlg.button_TrainModel.clicked.connect(self.train_model)
            # self.dlg.button_ExportModel.clicked.connect(self.train_model)
            self.dlg.button_RunTest.clicked.connect(self.test_model)
            self.dlg.button_Predict.clicked.connect(self.predict_model)
            self.dlg.comboBox_InputModel.currentTextChanged.connect(self.on_model_changed)
            self.dlg.button_ExportModel.clicked.connect(self.save_model)
            self.dlg.button_LoadModel.clicked.connect(self.load_model)

            # Init task queue
            self.task_queue = TaskQueue(self.dlg)

        self.dlg.Log("Plugin initialized.")

        os.chdir(os.path.dirname(os.path.abspath(__file__)))
        self.dlg.Log(f"Current working directory: {os.getcwd()}")

        # Fetch all layers, including those inside groups
        all_layers = self.get_all_layers_with_children(QgsProject.instance().layerTreeRoot().children())

        # Clear the contents of the comboBox and lineEdit from previous runs
        self.dlg.comboBox_InputGMI.clear()
        self.dlg.comboBox_InputSurfPrecip.clear()
        # self.dlg.lineEdit.clear()
        # Populate the comboBox with names of all the loaded layers
        self.dlg.comboBox_InputGMI.addItems([layer.name() for layer in all_layers])
        self.dlg.comboBox_TestGMI.addItems([layer.name() for layer in all_layers])
        self.dlg.comboBox_InputSurfPrecip.addItems([layer.name() for layer in all_layers])
        self.dlg.comboBox_TestSurfPrecip.addItems([layer.name() for layer in all_layers])
        self.dlg.comboBox_ForecastGMI.addItems([layer.name() for layer in all_layers])

        # Add the model options to the comboBox
        self.dlg.comboBox_InputModel.clear()
        self.dlg.comboBox_InputModel.addItems(["MLP Regressor", "SVM", "Random Forest", "Decision Tree", "AdaBoost"])

        # Set the file dialogs
        # self.dlg.fileWidget_TestOutput.setFilter("All files (*.*);;JPEG (*.jpg *.jpeg);;TIFF (*.tif);;netCFD(*.nc)")
        directory = self.get_project_or_working_directory()
        self.dlg.fileWidget_TestOutput.lineEdit().setValue(os.path.join(directory, 'Output'))
        self.dlg.fileWidget_ErrorOutput.lineEdit().setValue(os.path.join(directory, 'Output', 'error_output.nc'))
        self.dlg.fileWidget_ForecastOutput.lineEdit().setValue(os.path.join(directory, 'Output'))

        self.dlg.fileWidget_ExportModel.setFilter("Pickle files (*.pkl);;All files (*.*)")
        self.dlg.fileWidget_LoadModel.setFilter("Pickle files (*.pkl);;All files (*.*)")

        self.display_metrics_tables()

        # # write feature attributes
        # selectedLayerIndex = self.dlg.comboBox_InputGMI.currentIndex()
        # selectedLayer = layers[selectedLayerIndex].layer()
        # self.dlg.Log(selectedLayer.bandCount())
        # mask = True
        # self.dlg.Log(selectedLayer.as_numpy(mask, [1]))

        # show the dialog
        self.dlg.show()
        # Run the dialog event loop
        result = self.dlg.exec_()
        # See if OK was pressed
        if result:
            # Do something useful here - delete the line containing pass and
            # substitute with your code.
            pass
